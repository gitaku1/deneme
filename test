import os
import nbformat
from nbconvert import HTMLExporter
from weasyprint import HTML
from bs4 import BeautifulSoup

IPYNB_PATH = "/veri01/ipynbdirectory/notebook.ipynb"
PDF_OUTPUT_PATH = "/veri01/ipynbdirectory/only_outputs_cleaned.pdf"

BASE_CSS = """
<style>
@page {
    size: A4 portrait;
    margin: 1cm;
}
@page rotated {
    size: A4 landscape;
    margin: 1cm;
}
body {
    font-family: "DejaVu Sans", sans-serif;
    font-size: 9pt;
}
pre, code {
    font-size: 8pt !important;
    white-space: pre-wrap !important;
    word-wrap: break-word;
}
.output_area pre, .output_area div {
    white-space: pre-wrap !important;
    word-break: break-word !important;
    overflow-x: auto !important;
}
.output_scroll {
    overflow-x: auto !important;
    max-height: none !important;
}
.output_wrapper, .output {
    page-break-inside: avoid !important;
}
.table-wide {
    page: rotated;
    font-size: 7pt;
    width: 100%;
    table-layout: auto;
    display: block;
    overflow-x: auto;
}
table {
    width: 100%;
    word-wrap: break-word;
    font-size: 8pt;
    table-layout: auto;
}
td, th {
    padding: 2px;
    text-overflow: clip;
    overflow-wrap: break-word;
}
</style>
"""

LONG_OUTPUT_STYLE = 'font-size:6pt; line-height:1.1em;'
LONG_OUTPUT_CHAR_LIMIT = 5000
TABLE_COLUMN_LIMIT = 8

def convert_outputs_only_clean():
    print("ðŸ“˜ Notebook okunuyor...")
    with open(IPYNB_PATH, "r", encoding="utf-8") as f:
        nb = nbformat.read(f, as_version=4)

    html_exporter = HTMLExporter()
    html_exporter.exclude_input = True
    html_exporter.exclude_input_prompt = True
    html_exporter.exclude_output_prompt = True
    body, _ = html_exporter.from_notebook_node(nb)

    soup = BeautifulSoup(body, "html.parser")

    seen_outputs = set()
    cleaned_outputs = []

    print("ðŸ” Ã‡Ä±ktÄ±lar analiz ediliyor...")
    for output_div in soup.find_all("div", class_="output_area"):
        text = output_div.get_text(strip=True)
        if not text or text in seen_outputs:
            output_div.decompose()  # BoÅŸ veya tekrar eden outputâ€™u sil
            continue
        seen_outputs.add(text)

        if len(text) > LONG_OUTPUT_CHAR_LIMIT:
            for tag in output_div.find_all(["pre", "code", "div"]):
                tag['style'] = tag.get('style', '') + LONG_OUTPUT_STYLE

        cleaned_outputs.append(output_div)

    for table in soup.find_all("table"):
        header = table.find("tr")
        if header:
            columns = header.find_all(["td", "th"])
            if len(columns) >= TABLE_COLUMN_LIMIT:
                table['class'] = table.get('class', []) + ['table-wide']

    # Gereksiz boÅŸ alanlarÄ± da temizle
    for tag in soup.find_all():
        if not tag.get_text(strip=True) and not tag.name.startswith('img'):
            tag.decompose()

    print("ðŸ“„ TemizlenmiÅŸ PDF oluÅŸturuluyor...")
    final_html = BASE_CSS + str(soup)
    HTML(string=final_html).write_pdf(PDF_OUTPUT_PATH)
    print(f"âœ… PDF baÅŸarÄ±yla oluÅŸturuldu: {PDF_OUTPUT_PATH}")

convert_outputs_only_clean()
